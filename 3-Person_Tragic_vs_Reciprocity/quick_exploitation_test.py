"""
Quick test to demonstrate improved exploitation with enhanced Q-learning
"""

from enhanced_qlearning_agents import EnhancedQLearningAgent
from extended_agents import ExtendedNPersonAgent, QLearningNPersonWrapper
from main_neighbourhood import NPERSON_COOPERATE

def run_exploitation_test(config_name, config, num_rounds=1000):
    """Run a single exploitation test."""
    print(f"\n--- {config_name} ({num_rounds} rounds) ---")
    
    # Create agents
    ql_agent = EnhancedQLearningAgent(0, **config)
    ql_wrapper = QLearningNPersonWrapper(0, ql_agent)
    allc_agent1 = ExtendedNPersonAgent(1, "AllC", exploration_rate=0.01)
    allc_agent2 = ExtendedNPersonAgent(2, "AllC", exploration_rate=0.01)
    
    agents = [ql_wrapper, allc_agent1, allc_agent2]
    
    # Track progress
    cooperation_rates = []
    prev_coop_ratio = None
    
    for round_num in range(num_rounds):
        # Collect actions
        actions = {}
        for agent in agents:
            _, actual = agent.choose_action(prev_coop_ratio, round_num)
            actions[agent.agent_id] = actual
        
        # Calculate cooperation
        num_coops = sum(1 for action in actions.values() if action == NPERSON_COOPERATE)
        prev_coop_ratio = num_coops / len(agents)
        cooperation_rates.append(prev_coop_ratio)
        
        # Calculate payoffs
        for agent in agents:
            my_action = actions[agent.agent_id]
            others_coop = num_coops - (1 if my_action == NPERSON_COOPERATE else 0)
            
            if my_action == NPERSON_COOPERATE:
                payoff = 0 + 3 * (others_coop / (len(agents) - 1))
            else:
                payoff = 1 + 4 * (others_coop / (len(agents) - 1))
            
            agent.record_round_outcome(my_action, payoff)
    
    # Report results
    ql_coop_rate = ql_wrapper.get_cooperation_rate()
    ql_score = ql_wrapper.total_score
    final_epsilon = ql_wrapper.qlearning_agent.epsilon
    exploitation_rate = (1 - ql_coop_rate) * 100  # % defection
    
    print(f"  QL Cooperation Rate: {ql_coop_rate:.3f}")
    print(f"  QL Score: {ql_score:.1f}")
    print(f"  Exploitation Rate: {exploitation_rate:.1f}%")
    print(f"  Final Epsilon: {final_epsilon:.4f}")
    
    # Show final cooperation in last 100 rounds
    final_coop = sum(cooperation_rates[-100:]) / 100 if len(cooperation_rates) >= 100 else sum(cooperation_rates) / len(cooperation_rates)
    print(f"  Final 100-round avg cooperation: {final_coop:.3f}")
    
    return {
        'cooperation_rate': ql_coop_rate,
        'score': ql_score,
        'exploitation_rate': exploitation_rate,
        'final_epsilon': final_epsilon,
        'final_group_coop': final_coop
    }

def main():
    """Run comprehensive exploitation comparison."""
    print("Enhanced Q-Learning Exploitation Test")
    print("="*50)
    
    configs = [
        ("Baseline (Original)", {
            "exclude_self": False,
            "epsilon": 0.1,
            "epsilon_decay": 1.0,
            "opponent_modeling": False
        }),
        ("Exclude Self Only", {
            "exclude_self": True,
            "epsilon": 0.1,
            "epsilon_decay": 1.0,
            "opponent_modeling": False
        }),
        ("Epsilon Decay Only", {
            "exclude_self": False,
            "epsilon": 0.1,
            "epsilon_decay": 0.995,
            "epsilon_min": 0.01,
            "opponent_modeling": False
        }),
        ("Exclude Self + Decay", {
            "exclude_self": True,
            "epsilon": 0.1,
            "epsilon_decay": 0.995,
            "epsilon_min": 0.01,
            "opponent_modeling": False
        }),
        ("All Improvements", {
            "exclude_self": True,
            "epsilon": 0.1,
            "epsilon_decay": 0.995,
            "epsilon_min": 0.001,
            "opponent_modeling": True,
            "state_type": "fine"
        })
    ]
    
    results = {}
    
    # Run tests
    for name, config in configs:
        results[name] = run_exploitation_test(name, config, 2000)
    
    # Summary comparison
    print(f"\n{'='*70}")
    print("EXPLOITATION EFFECTIVENESS SUMMARY")
    print(f"{'='*70}")
    print(f"{'Configuration':<20} {'Exploit %':<10} {'Score':<8} {'Final Îµ':<10}")
    print(f"{'-'*70}")
    
    for name, result in results.items():
        print(f"{name:<20} {result['exploitation_rate']:<10.1f} {result['score']:<8.0f} {result['final_epsilon']:<10.4f}")
    
    # Theoretical maximum
    theoretical_max = 2000 * (1 + 4 * 1.0)  # Always defect vs 2 cooperators
    print(f"\nTheoretical maximum score: {theoretical_max:.0f}")
    print("(Achieved by always defecting against 2 AllC agents)")

if __name__ == "__main__":
    main()