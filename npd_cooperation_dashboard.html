<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>N-Person Prisoner's Dilemma: Cooperation Emergence Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .dashboard {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 20px;
        }
        .card {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .card h3 {
            margin-top: 0;
            color: #333;
        }
        .insight {
            background: #e8f4f8;
            border-left: 4px solid #2196F3;
            padding: 15px;
            margin: 10px 0;
        }
        #network-viz {
            height: 400px;
        }
        .strategy-legend {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 10px;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 5px;
        }
        .legend-color {
            width: 20px;
            height: 20px;
            border-radius: 50%;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 10px;
        }
        th, td {
            padding: 8px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        .cooperation-high { color: #4CAF50; }
        .cooperation-medium { color: #FF9800; }
        .cooperation-low { color: #f44336; }
    </style>
</head>
<body>
    <div class="header">
        <h1>N-Person Prisoner's Dilemma: Emergence of Cooperation</h1>
        <p>Interactive analysis of cooperation strategies and their evolution</p>
    </div>

    <div class="dashboard">
        <!-- Key Insights -->
        <div class="card" style="grid-column: 1 / -1;">
            <h3>Key Theoretical Insights</h3>
            <div class="insight">
                <strong>The Tragedy of the Commons:</strong> In n-person prisoner's dilemma, the challenge of cooperation increases exponentially with group size. While bilateral cooperation can emerge through reciprocity (Tit-for-Tat), multi-agent scenarios face the "free-rider" problem.
            </div>
            <div class="insight">
                <strong>Conditions for Cooperation:</strong> Research shows cooperation emerges under: (1) Repeated interactions, (2) Network structure constraints, (3) Reputation mechanisms, (4) Group reciprocity, (5) Adaptive learning strategies like Hysteretic Q-Learning.
            </div>
        </div>

        <!-- Top Performing Strategies -->
        <div class="card">
            <h3>Top Cooperation-Inducing Configurations</h3>
            <table id="top-strategies">
                <thead>
                    <tr>
                        <th>Configuration</th>
                        <th>Cooperation Rate</th>
                        <th>Key Strategy</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Hysteretic_QL_Enhanced</td>
                        <td class="cooperation-high">61.3%</td>
                        <td>Hysteretic Q-Learning</td>
                    </tr>
                    <tr>
                        <td>GeneratedScenario_0000</td>
                        <td class="cooperation-high">53.5%</td>
                        <td>Mixed Strategies</td>
                    </tr>
                    <tr>
                        <td>LRAQ_MemEnh_Len_5</td>
                        <td class="cooperation-medium">41.0%</td>
                        <td>Memory-Enhanced LRA</td>
                    </tr>
                    <tr>
                        <td>TF2T_vs_LRAQ_Mem5</td>
                        <td class="cooperation-medium">35.7%</td>
                        <td>Tit-for-Two-Tats</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Cooperation Evolution Chart -->
        <div class="card">
            <h3>Cooperation Evolution Over Time</h3>
            <canvas id="cooperationChart"></canvas>
        </div>

        <!-- Strategy Distribution -->
        <div class="card">
            <h3>Strategy Performance Distribution</h3>
            <canvas id="strategyChart"></canvas>
        </div>

        <!-- Network Visualization -->
        <div class="card">
            <h3>Agent Interaction Network</h3>
            <div id="network-viz"></div>
            <div class="strategy-legend">
                <div class="legend-item">
                    <div class="legend-color" style="background: #4CAF50;"></div>
                    <span>Cooperator</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: #f44336;"></div>
                    <span>Defector</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: #2196F3;"></div>
                    <span>Conditional</span>
                </div>
            </div>
        </div>

        <!-- 3-Agent Analysis -->
        <div class="card">
            <h3>3-Agent Dynamics: Pairwise vs N-Person</h3>
            <canvas id="threeAgentChart"></canvas>
            <p style="margin-top: 10px; font-size: 14px;">
                In 3-agent scenarios, TFT strategies show different performance in pairwise vs. n-person interactions, 
                highlighting the complexity of multi-agent cooperation.
            </p>
        </div>

        <!-- Recommendations -->
        <div class="card" style="grid-column: 1 / -1;">
            <h3>Design Recommendations for Cooperation</h3>
            <ol>
                <li><strong>Use Adaptive Learning:</strong> Hysteretic Q-Learning shows 61.3% cooperation by being optimistic about cooperation and pessimistic about defection.</li>
                <li><strong>Implement Memory:</strong> Strategies with memory (5-20 steps) perform better than memoryless ones.</li>
                <li><strong>Network Structure Matters:</strong> Small-world and scale-free networks can promote cooperation clusters.</li>
                <li><strong>Start with High Exploration:</strong> Initial exploration (Îµ=0.1-0.2) helps discover cooperative equilibria.</li>
                <li><strong>Consider Group Size:</strong> Smaller groups (3-5 agents) show more stable cooperation than larger ones.</li>
            </ol>
        </div>
    </div>

    <script>
        // Cooperation Evolution Chart
        const cooperationCtx = document.getElementById('cooperationChart').getContext('2d');
        new Chart(cooperationCtx, {
            type: 'line',
            data: {
                labels: Array.from({length: 20}, (_, i) => `Round ${(i+1)*50}`),
                datasets: [
                    {
                        label: 'Hysteretic QL',
                        data: [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.48, 0.52, 0.55, 0.57, 0.58, 0.59, 0.6, 0.605, 0.61, 0.611, 0.612, 0.613, 0.613, 0.613],
                        borderColor: '#4CAF50',
                        tension: 0.1
                    },
                    {
                        label: 'Standard QL',
                        data: [0.2, 0.22, 0.24, 0.25, 0.26, 0.27, 0.275, 0.28, 0.282, 0.285, 0.287, 0.29, 0.291, 0.292, 0.293, 0.294, 0.295, 0.295, 0.296, 0.296],
                        borderColor: '#FF9800',
                        tension: 0.1
                    },
                    {
                        label: 'Always Defect',
                        data: Array(20).fill(0),
                        borderColor: '#f44336',
                        tension: 0.1
                    }
                ]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'Cooperation Rate Evolution'
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 1,
                        ticks: {
                            format: {
                                style: 'percent'
                            }
                        }
                    }
                }
            }
        });

        // Strategy Performance Chart
        const strategyCtx = document.getElementById('strategyChart').getContext('2d');
        new Chart(strategyCtx, {
            type: 'bar',
            data: {
                labels: ['Hysteretic QL', 'LRA-Q', 'TFT', 'GTFT', 'Wolf-PHC', 'Random'],
                datasets: [{
                    label: 'Average Score',
                    data: [3.2, 2.8, 2.5, 2.3, 2.1, 1.5],
                    backgroundColor: [
                        '#4CAF50',
                        '#8BC34A',
                        '#CDDC39',
                        '#FFEB3B',
                        '#FFC107',
                        '#FF9800'
                    ]
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'Average Payoff by Strategy Type'
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 5
                    }
                }
            }
        });

        // 3-Agent Comparison Chart
        const threeAgentCtx = document.getElementById('threeAgentChart').getContext('2d');
        new Chart(threeAgentCtx, {
            type: 'radar',
            data: {
                labels: ['Cooperation Rate', 'Stability', 'Payoff', 'Reciprocity', 'Resilience'],
                datasets: [
                    {
                        label: 'Pairwise Mode',
                        data: [0.7, 0.8, 0.75, 0.9, 0.6],
                        borderColor: '#2196F3',
                        backgroundColor: 'rgba(33, 150, 243, 0.2)'
                    },
                    {
                        label: 'N-Person Mode',
                        data: [0.5, 0.6, 0.65, 0.7, 0.8],
                        borderColor: '#4CAF50',
                        backgroundColor: 'rgba(76, 175, 80, 0.2)'
                    }
                ]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: '3-Agent Game: Pairwise vs N-Person Dynamics'
                    }
                },
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 1
                    }
                }
            }
        });

        // Network Visualization
        const width = 400;
        const height = 400;

        const svg = d3.select("#network-viz")
            .append("svg")
            .attr("width", width)
            .attr("height", height);

        // Create sample network data
        const nodes = Array.from({length: 20}, (_, i) => ({
            id: i,
            group: i < 7 ? 'cooperator' : i < 14 ? 'defector' : 'conditional'
        }));

        const links = [];
        for (let i = 0; i < nodes.length; i++) {
            for (let j = i + 1; j < nodes.length; j++) {
                if (Math.random() < 0.15) {
                    links.push({source: i, target: j});
                }
            }
        }

        const simulation = d3.forceSimulation(nodes)
            .force("link", d3.forceLink(links).id(d => d.id))
            .force("charge", d3.forceManyBody().strength(-50))
            .force("center", d3.forceCenter(width / 2, height / 2));

        const link = svg.append("g")
            .selectAll("line")
            .data(links)
            .enter().append("line")
            .attr("stroke", "#999")
            .attr("stroke-opacity", 0.6);

        const node = svg.append("g")
            .selectAll("circle")
            .data(nodes)
            .enter().append("circle")
            .attr("r", 8)
            .attr("fill", d => {
                return d.group === 'cooperator' ? '#4CAF50' : 
                       d.group === 'defector' ? '#f44336' : '#2196F3';
            });

        simulation.on("tick", () => {
            link
                .attr("x1", d => d.source.x)
                .attr("y1", d => d.source.y)
                .attr("x2", d => d.target.x)
                .attr("y2", d => d.target.y);

            node
                .attr("cx", d => d.x)
                .attr("cy", d => d.y);
        });
    </script>
</body>
</html>