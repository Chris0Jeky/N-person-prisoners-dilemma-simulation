[
  {
    "scenario_name": "Evo_1744558684_3004",
    "num_agents": 20,
    "num_rounds": 200,
    "network_type": "random",
    "network_params": {
      "probability": 0.4
    },
    "interaction_mode": "neighborhood",
    "agent_strategies": {
      "tit_for_two_tats": 20,
      "ucb1_q": 15
    },
    "payoff_type": "linear",
    "payoff_params": {
      "T": 5,
      "R": 3,
      "P": 1,
      "S": -1
    },
    "state_type": "memory_enhanced",
    "memory_length": 3,
    "learning_rate": 0.05,
    "discount_factor": 0.8,
    "epsilon": 0.3,
    "q_init_type": "optimistic",
    "logging_interval": 301,
    "exploration_constant": 2.4
  },
  {
    "scenario_name": "Evo_1744558680_8844",
    "num_agents": 20,
    "num_rounds": 200,
    "network_type": "scale_free",
    "network_params": {
      "m": 2
    },
    "interaction_mode": "neighborhood",
    "agent_strategies": {
      "tit_for_two_tats": 7,
      "ucb1_q": 13
    },
    "payoff_type": "linear",
    "payoff_params": {
      "T": 5,
      "R": 3,
      "P": 1,
      "S": -1
    },
    "state_type": "memory_enhanced",
    "memory_length": 20,
    "learning_rate": 0.05,
    "discount_factor": 0.9,
    "epsilon": 0.3,
    "q_init_type": "optimistic",
    "logging_interval": 201,
    "exploration_constant": 2.4
  },
  {
    "scenario_name": "Evo_1744558682_4559",
    "num_agents": 20,
    "num_rounds": 200,
    "network_type": "random",
    "network_params": {
      "probability": 0.4
    },
    "interaction_mode": "neighborhood",
    "agent_strategies": {
      "always_defect": 1,
      "ucb1_q": 12,
      "tit_for_two_tats": 14
    },
    "payoff_type": "linear",
    "payoff_params": {
      "T": 5,
      "R": 3,
      "P": 1,
      "S": -1
    },
    "state_type": "memory_enhanced",
    "memory_length": 5,
    "learning_rate": 0.05,
    "discount_factor": 0.8,
    "epsilon": 0.3,
    "q_init_type": "zero",
    "logging_interval": 201,
    "exploration_constant": 2.4
  },
  {
    "scenario_name": "Evo_1744558678_9378",
    "num_agents": 20,
    "num_rounds": 200,
    "network_type": "random",
    "network_params": {
      "probability": 0.4
    },
    "interaction_mode": "neighborhood",
    "agent_strategies": {
      "tit_for_two_tats": 2,
      "ucb1_q": 18
    },
    "payoff_type": "linear",
    "payoff_params": {
      "T": 5,
      "R": 3,
      "P": 1,
      "S": -1
    },
    "state_type": "memory_enhanced",
    "memory_length": 20,
    "learning_rate": 0.05,
    "discount_factor": 0.9,
    "epsilon": 0.3,
    "q_init_type": "zero",
    "logging_interval": 201,
    "exploration_constant": 2.4
  },
  {
    "scenario_name": "GeneratedScenario_0014",
    "num_agents": 20,
    "num_rounds": 300,
    "network_type": "random",
    "network_params": {
      "probability": 0.7
    },
    "interaction_mode": "neighborhood",
    "agent_strategies": {
      "random": 1,
      "tit_for_tat": 19
    },
    "payoff_type": "linear",
    "payoff_params": {
      "R": 3,
      "S": 0,
      "T": 6,
      "P": 1
    },
    "state_type": "proportion_discretized",
    "memory_length": 10,
    "q_init_type": "optimistic",
    "learning_rate": 0.05,
    "discount_factor": 0.9,
    "epsilon": 0.3,
    "rewiring_interval": 50,
    "rewiring_prob": 0.15,
    "logging_interval": 301
  }
]